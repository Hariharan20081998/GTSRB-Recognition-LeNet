{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of LeNET5 for German traffic Sign.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "M94kdNIdNBum"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from sklearn.utils import shuffle\n",
        "#import pickle5 as pickle\n",
        "from sklearn.metrics import multilabel_confusion_matrix as confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.externals import joblib \n",
        "from google.colab import drive\n",
        "from keras.utils.np_utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUOVkumqLW7J"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjdhFIPMNCr1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b717cd5-1360-461d-bd6f-127033a93a00"
      },
      "source": [
        "#Importing the dataset\n",
        "\n",
        "train_set_x = pd.read_csv(r'/content/drive/My Drive/Model_Datasets/train_traffic_x.csv', header=None)\n",
        "test_set_x = pd.read_csv('/content/drive/My Drive/Model_Datasets/cropped_dataset.csv')\n",
        "train_set_y = pd.read_csv(r'/content/drive/My Drive/Model_Datasets/train_traffic_y.csv', header=None)\n",
        "test_set_y = pd.read_csv('/content/drive/My Drive/Model_Datasets/cropped_label.csv') \n",
        "print(\"Done reading .csv files\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done reading .csv files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2F5mdM9NE-5"
      },
      "source": [
        "#Splitting the dataset\n",
        "X_train = train_set_x.iloc[:,:].values\n",
        "y_train = train_set_y.iloc[:,-1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avKFJ_zIckoo"
      },
      "source": [
        "# Only to use for importing test_traffix_x.csv and test_traffix_y.csv\n",
        "test_dataset_y = pd.read_csv('/content/drive/My Drive/Model_Datasets/test_traffic_y.csv')\n",
        "test_dataset_x = pd.read_csv('/content/drive/My Drive/Model_Datasets/test_traffic_x.csv') \n",
        "X_dataset_test = test_dataset_x.iloc[:,:].values\n",
        "y_dataset_test = test_dataset_y.iloc[:,-1].values\n",
        "X_dataset_test = X_dataset_test.reshape(X_dataset_test.shape[0], 32, 32, 3)\n",
        "y_dataset_test = y_dataset_test.reshape(y_dataset_test.shape[0], 1)\n",
        "Y_dataset_test = to_categorical( y_dataset_test, num_classes = 43)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVwZiLi4jlU_"
      },
      "source": [
        "#Only to use when all_dataset.csv and all_label.csv is used\n",
        "X_test = test_set_x.to_numpy()\n",
        "y_test = test_set_y.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "palbyjl7NG9P"
      },
      "source": [
        "#Shaping X data and converting Y data to a one hot vector\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 32, 32, 3)\n",
        "X_test = X_test.reshape(X_test.shape[0], 32, 32, 3)\n",
        "y_train = y_train.reshape(y_train.shape[0], 1)\n",
        "y_test = y_test.reshape(y_test.shape[0], 1)\n",
        "X_train, y_train = shuffle(X_train, y_train, random_state=0)\n",
        "plt.imshow(X_train[223])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gahbNLvsLpx_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3989b106-7526-42e1-f598-f98cc7da9d3f"
      },
      "source": [
        "print(X_dataset_test.shape)\n",
        "print(Y_dataset_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12629, 32, 32, 3)\n",
            "(12629, 43)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZ9Dx9EfNJEf"
      },
      "source": [
        "#parameters specification\n",
        "batch_size = 32\n",
        "num_classes = 43\n",
        "epochs = 50\n",
        "img_size = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPtric96NK6M"
      },
      "source": [
        "#One hot encoding\n",
        "\n",
        "Y_train = to_categorical( y_train, num_classes = 43)\n",
        "Y_test = to_categorical( y_test, num_classes = 43)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Iyrzn1xNM14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "96f4cde4-4ba3-4bfb-c97f-40478e273376"
      },
      "source": [
        "#Developing the CNN model\n",
        "print(\"Devoloping a model\")\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Conv2D(6, kernel_size = (5, 5), activation='relu', input_shape=(img_size, img_size, 3)))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Conv2D(16, kernel_size = (5,5), activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(120, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "print(\"Model Developed\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Devoloping a model\n",
            "Model Developed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fH8ocb0Xk_XH"
      },
      "source": [
        "model.summary() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gb2mn4o9NO3k"
      },
      "source": [
        "#Compilation\n",
        "\n",
        "import keras\n",
        "from keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta\n",
        "\n",
        "opt = tf.keras.optimizers.Adagrad(lr=0.03)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics = ['accuracy'])\n",
        "\n",
        "#model.compile(loss='categorical_crossentropy',\n",
        "#              optimizer=keras.optimizers.SGD(lr=1e-3, momentum=0.9),\n",
        "#              metrics=['accuracy'])\n",
        "\n",
        "#opt = keras.optimizers.Adam(learning_rate=0.01)\n",
        "#model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history = model.fit(X_train, Y_train, batch_size=128, \n",
        "          epochs=50, verbose=1,validation_split=0.1)\n",
        "\n",
        "print(\"................TRAINING DONE....................\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J85qHfdzQlix"
      },
      "source": [
        "#Average Training Accuracy and Loss\n",
        "history.history['accuracy']\n",
        "accuracy = np.mean(history.history['accuracy'])\n",
        "print('The training accuracy is', accuracy*100)\n",
        "history.history['loss']\n",
        "loss = np.mean(history.history['loss'])\n",
        "print('The training loss is', loss)\n",
        "history.history['val_accuracy']\n",
        "val_accuracy = np.mean(history.history['val_accuracy'])\n",
        "print('The validation accuracy is', val_accuracy*100)\n",
        "history.history['val_loss']\n",
        "val_loss = np.mean(history.history['val_loss'])\n",
        "print('The validation loss is', val_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBD_B6Q0NR1g"
      },
      "source": [
        "#plotting the accuracy and loss\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7gL7u4fA5IiN"
      },
      "source": [
        "# Evaluation Metrics\n",
        "target_names = []\n",
        "for i in range(43):\n",
        "    a = 'Object '\n",
        "    b = str(i)\n",
        "    c = a+b\n",
        "    c = [i]\n",
        "    target_names.append((a+b))\n",
        "\n",
        "def reports(X_test,y_test):\n",
        "    Y_pred = model.predict(X_test)\n",
        "    y_pred = np.argmax(Y_pred, axis=1)\n",
        "    classification = classification_report(np.argmax(y_test, axis=1), y_pred, target_names=target_names)\n",
        "    confusion = confusion_matrix(np.argmax(y_test, axis=1), y_pred)\n",
        "    score = model.evaluate(X_test, y_test, batch_size=32)\n",
        "    Test_Loss = score[0]*100\n",
        "    Test_accuracy = score[1]*100\n",
        "    kc=cohen_kappa_score(np.argmax(y_test, axis=1), y_pred)\n",
        "    return classification, confusion, Test_Loss, Test_accuracy ,kc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQVwKXdCJrlz"
      },
      "source": [
        "# Testing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-X8wbfKKJrl0"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix,cohen_kappa_score\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, precision_score\n",
        "classification, confusion, Test_loss, Test_accuracy,kc = reports(X_dataset_test,Y_dataset_test)\n",
        "classification = str(classification)\n",
        "confusion_str = str(confusion)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mvNn_AtJJrl3"
      },
      "source": [
        "print(\"confusion matrix: \")\n",
        "print('{}'.format(confusion_str))\n",
        "print(\"KAppa Coeefecient=\",kc)\n",
        "print('Test loss {} (%)'.format(Test_loss))\n",
        "print('Test accuracy {} (%)'.format(Test_accuracy))\n",
        "print(classification)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cTMOv_QcJrl6"
      },
      "source": [
        "# Plot Confusion Matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "%matplotlib inline\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.get_cmap(\"Blues\")):\n",
        "    Normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    if normalize:\n",
        "        cm = Normalized\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "    plt.imshow(Normalized, interpolation='nearest', cmap=cmap)\n",
        "    plt.colorbar()\n",
        "    plt.title(title)\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=90)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        thresh = cm[i].max() / 2.\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "\n",
        "plt.figure(figsize=(17,17))\n",
        "plot_confusion_matrix(confusion, classes=target_names, normalize=False, \n",
        "                      title='Confusion matrix, without normalization')\n",
        "#plt.savefig(\"/content/drive/My Drive/results/InceptionResNetV2/caltech101/confusion_matrix_without_normalization.png\")\n",
        "plt.show()\n",
        "plt.figure(figsize=(25,25))\n",
        "plot_confusion_matrix(confusion, classes=target_names, normalize=True, \n",
        "                      title='Normalized confusion matrix')\n",
        "#plt.savefig(\"/content/drive/My Drive/results/InceptionResNetV2/caltech101/confusion_matrix_with_normalization.png\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHj8GgWjJhk0"
      },
      "source": [
        "# Cropped Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1TPax_WE5IiS"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix,cohen_kappa_score\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, precision_score\n",
        "classification, confusion, Test_loss, Test_accuracy,kc = reports(X_test,Y_test)\n",
        "classification = str(classification)\n",
        "confusion_str = str(confusion)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LlFEO7T05IiV"
      },
      "source": [
        "print(\"confusion matrix: \")\n",
        "print('{}'.format(confusion_str))\n",
        "print(\"KAppa Coeefecient=\",kc)\n",
        "print('Test loss {} (%)'.format(Test_loss))\n",
        "print('Test accuracy {} (%)'.format(Test_accuracy))\n",
        "print(classification)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CqPDcsFr5IiX"
      },
      "source": [
        "# Plit Confusion Matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "%matplotlib inline\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.get_cmap(\"Blues\")):\n",
        "    Normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    if normalize:\n",
        "        cm = Normalized\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "    plt.imshow(Normalized, interpolation='nearest', cmap=cmap)\n",
        "    plt.colorbar()\n",
        "    plt.title(title)\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=90)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        thresh = cm[i].max() / 2.\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "\n",
        "plt.figure(figsize=(17,17))\n",
        "plot_confusion_matrix(confusion, classes=target_names, normalize=False, \n",
        "                      title='Confusion matrix, without normalization')\n",
        "#plt.savefig(\"/content/drive/My Drive/results/InceptionResNetV2/caltech101/confusion_matrix_without_normalization.png\")\n",
        "plt.show()\n",
        "plt.figure(figsize=(25,25))\n",
        "plot_confusion_matrix(confusion, classes=target_names, normalize=True, \n",
        "                      title='Normalized confusion matrix')\n",
        "#plt.savefig(\"/content/drive/My Drive/results/InceptionResNetV2/caltech101/confusion_matrix_with_normalization.png\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}